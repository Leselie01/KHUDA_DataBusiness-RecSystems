{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157ec75e",
   "metadata": {},
   "source": [
    "# 9장. 잠재고객을 파악하기 위한 이미지 인식 테크닉 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8311eb",
   "metadata": {},
   "source": [
    "## 81: 이미지 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb3bb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\cyg01\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\cyg01\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c5129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 가로: 1920\n",
      "이미지 세로: 1440\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"img/img01.jpg\")\n",
    "height, width = img.shape[:2]\n",
    "print(\"이미지 가로: \" + str(width))\n",
    "print(\"이미지 세로: \" + str(height)) \n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad04bd68",
   "metadata": {},
   "source": [
    "- cv2: a popular library for image and video processing tasks in Python\n",
    "- img.shape: returns the dimensions of the image as a tuple (height, width, channels->color channels)\n",
    "    - img.shape[:2]: (height, width)만 추출\n",
    "- imshow(): displays the image\n",
    "    - (note) cv2.imshow() often doesn’t work as expected for displaying images, since it requires a separate GUI window that Jupyter Notebook doesn’t natively support\n",
    "- waitKey: 몇 초 동안 이미지를 표시할지 밀리초 단위로 지정\n",
    "    - 인수에 0을 지정할 시, 윈도우를 닫을 때까지 계속해서 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f5c72a",
   "metadata": {},
   "source": [
    "## 82: 동영상 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63025aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 정보 취득\n",
    "cap = cv2.VideoCapture(\"mov/mov01.avi\")\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"가로: \" + str(width))\n",
    "print(\"세로: \" + str(height))\n",
    "print(\"총 프레임수: \" + str(count))\n",
    "print(\"FPS: \" + str(fps))\n",
    "\n",
    "# 출력\n",
    "while(cap.isOpened()): #iterates as long as the video file is open&readable\n",
    "    ret, frame = cap.read() \n",
    "    if ret:\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de1a1c1",
   "metadata": {},
   "source": [
    "- cap.get(): extract specific properties of the video\n",
    "- cv2.CAP_PROP_FRAME_WIDTH: 각 video frame의 width\n",
    "- cv2.CAP_PROP_FRAME_COUNT: num of frames in the video\n",
    "- cap.read(): reads the next frame of the video\n",
    "    - ret: boolean. True: frame was read, False: no more frames\n",
    "    - frame: the actual frame image captured from the video\n",
    "- cv2.waitKey(1): waits 1 ms between frames -> real-time video display\n",
    "- cv2.waitKey(1) & 0xFF == ord(\"q\"): checks if the \"q\" key was pressed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13fab31",
   "metadata": {},
   "source": [
    "## 83: 동영상을 이미지로 나누고 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca3e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(\"mov/mov01.avi\")\n",
    "num = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        filepath = \"snapshot/snapshot_\" + str(num) + \".jpg\"\n",
    "        cv2.imwrite(filepath,frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    num = num + 1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057dc34",
   "metadata": {},
   "source": [
    "- cap.release(): 객체가 잡고 있던 비디오 파일 리소스 해제\n",
    "- cv2.destroyAllWindows(): OpenCV에서 생성한 모든 창 닫음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44defce2",
   "metadata": {},
   "source": [
    "## 84: 이미지 속에 사람이 어디에 있는지 검출하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b09f867",
   "metadata": {},
   "source": [
    "이미지에서 사람을 검출하여 각 사람 영역에 사각형을 그린 후 화면에 표시하고, 결과를 파일로 저장하는 프로그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0b82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 준비\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "hogParams = {'winStride': (8,8), 'padding': (32, 32), 'scale':1.05, 'hitThreshold':0, 'finalThreshold':5}\n",
    "\n",
    "# 검출\n",
    "img = cv2.imread(\"img/img01.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "human, r = hog.detectMultiScale(gray, **hogParams)\n",
    "if (len(human)>0):\n",
    "    for (x, y, w, h) in human:\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (255, 255, 255), 3)\n",
    "        \n",
    "cv2.namedWindow(\"img\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imwrite(\"temp.jpg\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d660f93",
   "metadata": {},
   "source": [
    "- HOGDescriptor()\n",
    "    - Histogram of Oriented Gradients 라는 이미지 특성을 추출하기 위한 기법을 구현한 OpenCV의 클래스\n",
    "    - 이미지에서 물체(특히 사람)의 윤곽과 같은 특정 패턴을 인식하는 데 유용하게 사용\n",
    "- hog.setSVMDetector: 사람 검출을 위한 사전 학습된 SVM (Support Vector Machine) 모델선정\n",
    "- hogParams로 HOG 검출에 필요한 여러 파라메터를 딕셔너리 형태로 정의\n",
    "- cv2.cvtColor: 그레이스케일로 변환\n",
    "    - 그레이스케일: 흑백 이미지를 나타내는 방식\n",
    "    - 각 픽셀의 밝기 정보만을 포함하여 이미지 표현\n",
    "- hog.detectMultiScale: 사람 검출\n",
    "    - human: 검출된 객체들의 좌표 (x, y, w, h)가 리스트로 반환\n",
    "    - 각 좌표는 각각 검출된 사람의 위치와 크기\n",
    "- cv2.hectangle: 각 검출된 영역에 대해 (x, y, w, h)좌표에 흰색 사각형을 그려 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98b14c",
   "metadata": {},
   "source": [
    "## 85: 이미지 속 사람 얼굴 검출\n",
    "- 전통적으로 CascadeClassifier 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791ec68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#준비\n",
    "cascade_file = \"haarcascade_frontalface_alt.xml\"\n",
    "cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "#검출\n",
    "img = cv2.imread(\"img/img02.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "face_list = cascade.detectMultiScale(gray, minSize=(50, 50))\n",
    "\n",
    "#검출한 얼굴 표시하기\n",
    "for (x, y, w, h) in face_list:\n",
    "    color = (0, 0, 225)\n",
    "    pen_w = 3\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), color, thickness = pen_w)\n",
    "cv2.namedWindow(\"img\",cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"img\",img)\n",
    "cv2.imwrite(\"temp.jpg\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d120559e",
   "metadata": {},
   "source": [
    "- cv2.CascadeClassifier(): OpenCV에서 Haar Cascade 분류기를 불러오는 클래스\n",
    "- cascade.detectMultiScale(): 이미지를 탐색하여 얼굴을 검출하는 함수\n",
    "    - 얼굴이 컴출되면 (x, y, w, h)좌표로 반환\n",
    "    - minsize=(50, 50): 검출할 얼굴의 최소 크기를 (50, 50)으로 지정 -> 너무 작은 객체는 거름\n",
    "- cv2.rectangle\n",
    "    - (x,y): 사각형의 왼쪽 위 모서리\n",
    "    - (x+w, y+h): 오른쪽 아래 모서리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7de6a8",
   "metadata": {},
   "source": [
    "## 86: 이미지 속 사람의 얼굴이 어느 쪽을 보고 있는지 검출\n",
    "- dib 라이브러리: 얼굴을 얼굴 랜드마크 (눈, 코, 입, 윤곽)의 68개 특징점으로 표현 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88354448",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c8b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89908ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 준비 #\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# 검출 #\n",
    "img = cv2.imread(\"img/img02.jpg\")\n",
    "dets = detector(img, 1)\n",
    "\n",
    "for k, d in enumerate(dets):\n",
    "    shape = predictor(img, d)\n",
    "\n",
    "    # 얼굴 영역 표시\n",
    "    color_f = (0, 0, 225)\n",
    "    color_l_out = (255, 0, 0)\n",
    "    color_l_in = (0, 255, 0)\n",
    "    line_w = 3\n",
    "    circle_r = 3\n",
    "    fontType = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontSize = 1\n",
    "    cv2.rectangle(img, (d.left(), d.top()), (d.right(), d.bottom()), color_f, line_w)\n",
    "    cv2.putText(img, str(k), (d.left(), d.top()), fontType, fontSize, color_f, line_w)\n",
    "\n",
    "    # 중심을 계산할 사각형 준비\n",
    "    num_of_points_out = 17\n",
    "    num_of_points_in = shape.num_parts - num_of_points_out\n",
    "    gx_out = 0\n",
    "    gy_out = 0\n",
    "    gx_in = 0\n",
    "    gy_in = 0\n",
    "    for shape_point_count in range(shape.num_parts):\n",
    "        shape_point = shape.part(shape_point_count)\n",
    "        #print(\"얼굴 랜드마크No.{} 좌표 위치: ({},{})\".format(shape_point_count, shape_point.x, shape_point.y))\n",
    "        #얼굴 랜드마크마다 그리기\n",
    "        if shape_point_count<num_of_points_out:\n",
    "            cv2.circle(img,(shape_point.x, shape_point.y),circle_r,color_l_out, line_w)\n",
    "            gx_out = gx_out + shape_point.x/num_of_points_out\n",
    "            gy_out = gy_out + shape_point.y/num_of_points_out\n",
    "        else:\n",
    "            cv2.circle(img,(shape_point.x, shape_point.y),circle_r,color_l_in, line_w)\n",
    "            gx_in = gx_in + shape_point.x/num_of_points_in\n",
    "            gy_in = gy_in + shape_point.y/num_of_points_in\n",
    "\n",
    "    # 중심 위치 표시\n",
    "    cv2.circle(img,(int(gx_out), int(gy_out)),circle_r,(0,0,255), line_w)\n",
    "    cv2.circle(img,(int(gx_in), int(gy_in)),circle_r,(0,0,0), line_w)\n",
    "\n",
    "    # 얼굴 방향 계산\n",
    "    theta = math.asin(2*(gx_in-gx_out)/(d.right()-d.left()))\n",
    "    radian = theta*180/math.pi\n",
    "    print(\"얼굴 방향:{} (각도:{}도)\".format(theta,radian))\n",
    "\n",
    "    # 얼굴 방향 표시\n",
    "    if radian<0:\n",
    "        textPrefix = \"   left \"\n",
    "    else:\n",
    "        textPrefix = \"   right \"\n",
    "    textShow = textPrefix + str(round(abs(radian),1)) + \" deg.\"\n",
    "    cv2.putText(img, textShow, (d.left(), d.top()), fontType, fontSize, color_f, line_w)\n",
    "\n",
    "\n",
    "# cv2.imshow(\"img\",img)\n",
    "# cv2.imwrite(\"temp.jpg\",img)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "cv2.namedWindow(\"img\",cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"img\",img)\n",
    "cv2.imwrite(\"temp.jpg\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715de5b5",
   "metadata": {},
   "source": [
    "- enumerate(dets): 여러 얼굴을 검출할 수 있으므로, dets의 각 얼굴 위치와 인덱스를 함께 반환\n",
    "    - enumerate: 파이썬 내장 함수. 반복문에서 리스트나 다른 iterable 객체의 인덱스와 값을 함께 반환\n",
    "- predictor(img,d): predictor을 사용해 d 영역에서 얼굴 랜드마크를 찾고, shape 객체로 반환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d2948",
   "metadata": {},
   "source": [
    "## 87: 검출한 정보를 종합해서 타임랩스 만들기\n",
    "- 타임랩스: 일정 기간의 프레임 중에서 1 프레임만 꺼내는 '빠르게 재생하기'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576a378f",
   "metadata": {},
   "source": [
    "주어진 동영상에서 사람이 검출된 프레임을 간격을 두고 추출하여 새로운 타임랩스 영상을 만듦\n",
    "- HOGDescriptor: 사람을 검출하기 위해 설정됨\n",
    "- hogParrams: HOG 긱반 검출기의 파라미터 지정\n",
    "-> 동영상 프레임에서 사람을 찾고 사각형으로 표시\n",
    "- cv2.VideoWriter_fourcc, cv2.VideoWriter -> 새 동영상 파일 작성\n",
    "    - FourCC라고 부르는 네 개의 데이터 포맷을 지정하여 동영상 파일 작성 가능\n",
    "    - X, V, I, D 로 네 가지 파라미터 지정, AVI 형식으로 동영상 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ffb5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "print(\"타임랩스 생성 시작\")\n",
    "\n",
    "# 동영상 읽어오기 \n",
    "cap = cv2.VideoCapture(\"mov/mov01.avi\")\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# hog 선언 \n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05, 'hitThreshold':0, 'finalThreshold':5}\n",
    "\n",
    "# 타임랩스 작성 \n",
    "movie_name = \"timelapse.avi\"\n",
    "fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D')\n",
    "video = cv2.VideoWriter(movie_name,fourcc, 30, (width,height))\n",
    "\n",
    "num = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        if (num%10==0):\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            human, r = hog.detectMultiScale(gray, **hogParams)\n",
    "            if (len(human)>0):\n",
    "                for (x, y, w, h) in human:\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255,255,255), 3)\n",
    "\n",
    "            video.write(frame)\n",
    "    else:\n",
    "        break\n",
    "    num = num + 1\n",
    "video.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"타임랩스 생성 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace1c1e",
   "metadata": {},
   "source": [
    "## 88: 전체 모습을 그래프로 가시화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af1eca",
   "metadata": {},
   "source": [
    "### 사람 검출 결과를 데이터 프레임에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82380963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "print(\"분석 시작\")\n",
    "# 동영상 읽어오기 #\n",
    "cap = cv2.VideoCapture(\"mov/mov01.avi\")\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# hog 선언 \n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05, 'hitThreshold':0, 'finalThreshold':5}\n",
    "\n",
    "num = 0\n",
    "list_df = pd.DataFrame( columns=['time','people'] )\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        if (num%10==0):\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            human, r = hog.detectMultiScale(gray, **hogParams)\n",
    "            if (len(human)>0):\n",
    "                for (x, y, w, h) in human:\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255,255,255), 3)\n",
    "            tmp_se = pd.Series( [num/fps,len(human) ], index=list_df.columns )\n",
    "            list_df = list_df.append( tmp_se, ignore_index=True )       \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    else:\n",
    "        break\n",
    "    num = num + 1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"분석 종료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a3012b",
   "metadata": {},
   "source": [
    "1. 동영상 파일 읽기 및 FPS 설정, 시간을 프레임에 따라 계산\n",
    "2. HOG 검출기 선언으로 사람을 검출하고, 특정 파라미터로 사람을 찾도록 설정\n",
    "3. 프레임 반복\n",
    "4. pd.Series를 통해 각 시간에 검출된 사람의 수를 df에 추가\n",
    "5. 결과 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0734fd43",
   "metadata": {},
   "source": [
    "### 그래프 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc36754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list_df[\"time\"], list_df[\"people\"])\n",
    "plt.xlabel('time(sec.)')\n",
    "plt.ylabel('population')\n",
    "plt.ylim(0,15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33b951b",
   "metadata": {},
   "source": [
    "## 89: 거리의 변화를 그래프로 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6196f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "print(\"분석 시작\")\n",
    "# 동영상 읽어오기 \n",
    "cap = cv2.VideoCapture(\"mov/mov02.avi\")\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# hog 선언 \n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05, 'hitThreshold':0, 'finalThreshold':5}\n",
    "\n",
    "num = 0\n",
    "list_df2 = pd.DataFrame( columns=['time','people'] )\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        if (num%10==0):\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            human, r = hog.detectMultiScale(gray, **hogParams)\n",
    "            if (len(human)>0):\n",
    "                for (x, y, w, h) in human:\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (255,255,255), 3)\n",
    "            tmp_se = pd.Series( [num/fps,len(human) ], index=list_df.columns )\n",
    "            list_df2 = list_df2.append( tmp_se, ignore_index=True )       \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    else:\n",
    "        break\n",
    "    num = num + 1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"분석 종료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca88247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list_df2[\"time\"], list_df2[\"people\"])\n",
    "plt.xlabel('time(sec.)')\n",
    "plt.ylabel('population')\n",
    "plt.ylim(0,15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f72e085",
   "metadata": {},
   "source": [
    "## 90: 이동 평균을 계산해서 노이즈 제거하기\n",
    "- 노이즈: 계산할 사람을 계산하지 않아서 생기는 오차, 계산하지 않아도 될 것을 계산해서 생기는 오차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def moving_average(x, y):\n",
    "    y_conv = np.convolve(y, np.ones(5)/float(5), mode='valid')\n",
    "    x_dat = np.linspace(np.min(x), np.max(x), np.size(y_conv))\n",
    "    return x_dat, y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1be2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list_df[\"time\"], list_df[\"people\"], label=\"raw\")\n",
    "ma_x, ma_y = moving_average(list_df[\"time\"], list_df[\"people\"])\n",
    "plt.plot(ma_x,ma_y, label=\"average\")\n",
    "plt.xlabel('time(sec.)')\n",
    "plt.ylabel('population')\n",
    "plt.ylim(0,15)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb186f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list_df2[\"time\"], list_df2[\"people\"], label=\"raw\")\n",
    "ma_x2, ma_y2 = moving_average(list_df2[\"time\"], list_df2[\"people\"])\n",
    "plt.plot(ma_x2,ma_y2, label=\"average\")\n",
    "plt.xlabel('time(sec.)')\n",
    "plt.ylabel('population')\n",
    "plt.ylim(0,15)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98532e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ma_x,ma_y, label=\"1st\")\n",
    "plt.plot(ma_x2,ma_y2, label=\"2nd\")\n",
    "plt.xlabel('time(sec.)')\n",
    "plt.ylabel('population')\n",
    "plt.ylim(0,15)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ed479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
